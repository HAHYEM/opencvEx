{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\bld\\opencv_1520732670222\\work\\opencv-3.4.1\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e9060199afd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mgray2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequalizeHist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\bld\\opencv_1520732670222\\work\\opencv-3.4.1\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "# smile 뜨게 만드는 작업 했어욯ㅎㅎ\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "eyeCascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_eye.xml')\n",
    "mouthCascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_mcs_mouth.xml')\n",
    "\n",
    "def Rotate(src, degrees):\n",
    "    if degrees == 90:\n",
    "        dst = cv2.transpose(src) # 행렬 변경 \n",
    "        dst = cv2.flip(dst, 1)   # 뒤집기\n",
    "\n",
    "    elif degrees == 180:\n",
    "        dst = cv2.flip(src, 0)   # 뒤집기\n",
    "\n",
    "    elif degrees == 270:\n",
    "        dst = cv2.transpose(src) # 행렬 변경\n",
    "        dst = cv2.flip(dst, 0)   # 뒤집기\n",
    "    else:\n",
    "        dst = null\n",
    "    return dst\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture('HUN.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "def findMouth(frame, eyes, faces):\n",
    "    mouths = mouthCascade.detectMultiScale(\n",
    "            frame,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=8,\n",
    "            minSize=(30, 10),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    if len(mouths) <= 0:\n",
    "        return 0, 0, 0, 0\n",
    "\n",
    "    eyeBottom = 0\n",
    "\n",
    "    for eye in eyes:\n",
    "        eyeX, eyeY, eyeW, eyeH = eye\n",
    "        if (eyeY + eyeH) > eyeBottom:\n",
    "            eyeBottom = eyeY + eyeH\n",
    "\n",
    "    faceX, faceY, faceW, faceH = faces[0]\n",
    "    faceBottom = faceY + faceH\n",
    "\n",
    "    for mouth in mouths:\n",
    "        mouthX, mouthY, mouthW, mouthH = mouth\n",
    "        if mouthY > (eyeBottom + 50) and (mouthY + mouthH) < faceBottom:\n",
    "            return mouth\n",
    "\n",
    "    return 0, 0, 0, 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "        frame = Rotate(frame,90)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.equalizeHist(gray)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=6,\n",
    "            minSize=(50, 50),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        eyes = eyeCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=6,\n",
    "            minSize=(50, 50),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "\n",
    "        # Draw a rectangle around the faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "        # Draw a rectangle around the eyes\n",
    "        if len(eyes) >= 2:\n",
    "            eyes = eyes[:2]\n",
    "        for (x, y, w, h) in eyes:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        \n",
    "        # Draw a rectangle around the mouth\n",
    "        if len(faces) > 0 and len(eyes) > 0:\n",
    "            x, y, w, h = findMouth(gray2, eyes, faces)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame,'Smile',(x,y-7), 3, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fe5c7376d0f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mcrop_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mgrey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# 손인식인데 되지 않아.. 실행이 되지 않아ㅠㅠ\n",
    "# 근데...어깨가 인식이 되넹ㅎㅎㅎ\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def Rotate(src, degrees):\n",
    "    if degrees == 90:\n",
    "        dst = cv2.transpose(src) # 행렬 변경 \n",
    "        dst = cv2.flip(dst, 1)   # 뒤집기\n",
    "\n",
    "    elif degrees == 180:\n",
    "        dst = cv2.flip(src, 0)   # 뒤집기\n",
    "\n",
    "    elif degrees == 270:\n",
    "        dst = cv2.transpose(src) # 행렬 변경\n",
    "        dst = cv2.flip(dst, 0)   # 뒤집기\n",
    "    else:\n",
    "        dst = null\n",
    "    return dst\n",
    "cap = cv2.VideoCapture('HUN.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    img = Rotate(img,90)\n",
    "    cv2.rectangle(img,(400,400),(200,200),(0,255,0),0)\n",
    "    crop_img = img[300:500, 150:360]\n",
    "    grey = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    value = (35, 35)\n",
    "    blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "    _, thresh1 = cv2.threshold(blurred, 127, 255,\n",
    "                               cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    cv2.imshow('Thresholded', thresh1)\n",
    "    _,contours, hierarchy = cv2.findContours(thresh1.copy(),cv2.RETR_TREE, \\\n",
    "            cv2.CHAIN_APPROX_NONE)\n",
    "    max_area = -1\n",
    "    for i in range(len(contours)):\n",
    "        cnt=contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area>max_area):\n",
    "            max_area=area\n",
    "            ci=i\n",
    "    cnt=contours[ci]\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(crop_img,(x,y),(x+w,y+h),(0,0,255),0)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    drawing = np.zeros(crop_img.shape,np.uint8)\n",
    "    cv2.drawContours(drawing,[cnt],0,(0,255,0),0)\n",
    "    cv2.drawContours(drawing,[hull],0,(0,0,255),0)\n",
    "    hull = cv2.convexHull(cnt,returnPoints = False)\n",
    "    defects = cv2.convexityDefects(cnt,hull)\n",
    "    count_defects = 0\n",
    "    cv2.drawContours(thresh1, contours, -1, (0,255,0), 3)\n",
    "    for i in range(defects.shape[0]):\n",
    "        s,e,f,d = defects[i,0]\n",
    "        start = tuple(cnt[s][0])\n",
    "        end = tuple(cnt[e][0])\n",
    "        far = tuple(cnt[f][0])\n",
    "        a = math.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "        b = math.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "        c = math.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "        angle = math.acos((b**2 + c**2 - a**2)/(2*b*c)) * 57\n",
    "        if angle <= 90:\n",
    "            count_defects += 1\n",
    "            cv2.circle(crop_img,far,1,[0,0,255],-1)\n",
    "        #dist = cv2.pointPolygonTest(cnt,far,True)\n",
    "        cv2.line(crop_img,start,end,[0,255,0],2)\n",
    "        #cv2.circle(crop_img,far,5,[0,0,255],-1)\n",
    "    if count_defects == 1:\n",
    "        cv2.putText(img,\"I'M VIKRANT SHARMA\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    elif count_defects == 2:\n",
    "        str = \"THIS IS A BASIC HAND GESTURE RECOGNISER!!\"\n",
    "        cv2.putText(img, str, (5,50), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    elif count_defects == 3:\n",
    "        cv2.putText(img,\"This is FOUR (:\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    elif count_defects == 4:\n",
    "        cv2.putText(img,\"HARE KRSNA\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    else:\n",
    "        cv2.putText(img,\"GOOD AFTERNOON TEACHERS\", (50,50),\\\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    #cv2.imshow('drawing', drawing)\n",
    "    #cv2.imshow('end', crop_img)\n",
    "    cv2.imshow('Gesture', img)\n",
    "    all_img = np.hstack((drawing, crop_img))\n",
    "    cv2.imshow('Contours', all_img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "VideoCapture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#이미지에서 다리인식하기\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('people.jpg',0)\n",
    "\n",
    "upperBody_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_lowerbody.xml')    \n",
    "\n",
    "arrUpperBody = upperBody_cascade.detectMultiScale(img)\n",
    "if arrUpperBody != ():\n",
    "        for (x,y,w,h) in arrUpperBody:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image is not a numpy array, neither a scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5dce82d53cb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mupperBody_cascade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_lowerbody.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0marrUpperBody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupperBody_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0marrUpperBody\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrUpperBody\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: image is not a numpy array, neither a scalar"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손인식인데 되지 않아.. 실행이 되지 않아ㅠㅠ\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "capture = cv2.VideoCapture('HUN.mp4')\n",
    "\n",
    "while():\n",
    "    \n",
    "    # Capture frames from the camera\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    # Get hand data from the rectangle sub window   \n",
    "    cv2.rectangle(frame,(100,100),(300,300),(0,255,0),0)\n",
    "    crop_image = frame[100:300, 100:300]\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blur = cv2.GaussianBlur(crop_image, (3,3), 0)\n",
    "    \n",
    "    # Change color-space from BGR -> HSV\n",
    "    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create a binary image with where white will be skin colors and rest is black\n",
    "    mask2 = cv2.inRange(hsv, np.array([2,0,0]), np.array([20,255,255]))\n",
    "    \n",
    "    # Kernel for morphological transformation    \n",
    "    kernel = np.ones((5,5))\n",
    "    \n",
    "    # Apply morphological transformations to filter out the background noise\n",
    "    dilation = cv2.dilate(mask2, kernel, iterations = 1)\n",
    "    erosion = cv2.erode(dilation, kernel, iterations = 1)    \n",
    "       \n",
    "    # Apply Gaussian Blur and Threshold\n",
    "    filtered = cv2.GaussianBlur(erosion, (3,3), 0)\n",
    "    ret,thresh = cv2.threshold(filtered, 127, 255, 0)\n",
    "    \n",
    "    # Show threshold image\n",
    "    cv2.imshow(\"Thresholded\", thresh)\n",
    "\n",
    "    # Find contours\n",
    "    image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE )\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Find contour with maximum area\n",
    "        contour = max(contours, key = lambda x: cv2.contourArea(x))\n",
    "        \n",
    "        # Create bounding rectangle around the contour\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(crop_image,(x,y),(x+w,y+h),(0,0,255),0)\n",
    "        \n",
    "        # Find convex hull\n",
    "        hull = cv2.convexHull(contour)\n",
    "        \n",
    "        # Draw contour\n",
    "        drawing = np.zeros(crop_image.shape,np.uint8)\n",
    "        cv2.drawContours(drawing,[contour],-1,(0,255,0),0)\n",
    "        cv2.drawContours(drawing,[hull],-1,(0,0,255),0)\n",
    "        \n",
    "        # Find convexity defects\n",
    "        hull = cv2.convexHull(contour, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(contour,hull)\n",
    "        \n",
    "        # Use cosine rule to find angle of the far point from the start and end point i.e. the convex points (the finger \n",
    "        # tips) for all defects\n",
    "        count_defects = 0\n",
    "        \n",
    "        for i in range(defects.shape[0]):\n",
    "            s,e,f,d = defects[i,0]\n",
    "            start = tuple(contour[s][0])\n",
    "            end = tuple(contour[e][0])\n",
    "            far = tuple(contour[f][0])\n",
    "\n",
    "            a = math.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "            b = math.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "            c = math.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "            angle = (math.acos((b**2 + c**2 - a**2)/(2*b*c))*180)/3.14\n",
    "            \n",
    "            # if angle > 90 draw a circle at the far point\n",
    "            if angle <= 90:\n",
    "                count_defects += 1\n",
    "                cv2.circle(crop_image,far,1,[0,0,255],-1)\n",
    "\n",
    "            cv2.line(crop_image,start,end,[0,255,0],2)\n",
    "\n",
    "        # Print number of fingers\n",
    "        if count_defects == 0:\n",
    "            cv2.putText(frame,\"HELLO\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        elif count_defects == 1:\n",
    "            cv2.putText(frame,\"TWO\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        elif count_defects == 2:\n",
    "            cv2.putText(frame, \"THREE\", (5,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        elif count_defects == 3:\n",
    "            cv2.putText(frame,\"FOUR\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        elif count_defects == 4:\n",
    "            cv2.putText(frame,\"FIVE\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # Show required images\n",
    "    cv2.imshow(\"Gesture\", frame)\n",
    "    all_image = np.hstack((drawing, crop_image))\n",
    "    cv2.imshow('Contours', all_image)\n",
    "      \n",
    "    # Close the camera if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (320,262,3) into shape (140,262,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-155b3a263642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mframe2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#2배로 만들기\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mframe1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Face Detector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (320,262,3) into shape (140,262,3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "#상체 탐지(영상)\n",
    "conda_path = 'D:\\\\javaForever\\\\util\\\\opencv\\\\sources\\\\data\\\\haarcascades\\\\'\n",
    "upper_cascade = cv2.CascadeClassifier(conda_path + 'haarcascade_upperbody.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('HUN.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame1 = cv2.resize(frame1, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        upper_rects = upper_cascade.detectMultiScale(gray, 1.1, 1)\n",
    "        \n",
    "        copy_x=0\n",
    "        copy_y=0\n",
    "        copy_w=0\n",
    "        copy_h=0\n",
    "\n",
    "        for(x, y, w, h) in upper_rects:\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 0)\n",
    "            copy_x = x\n",
    "            copy_y = y\n",
    "            copy_w = w\n",
    "            copy_h = h\n",
    "        \n",
    "            frame2 = frame1[copy_y : copy_y+copy_h, copy_x : copy_x+copy_w]\n",
    "\n",
    "            frame2 = cv2.resize(frame2, (2*frame2.shape[0], 2*frame2.shape[1]), interpolation = cv2.INTER_CUBIC) #2배로 만들기\n",
    "\n",
    "            frame1[100:100+frame2.shape[0], 100:100+frame2.shape[1]] = frame2[:frame2.shape[0], :frame2.shape[1]]\n",
    "            \n",
    "        cv2.imshow('Face Detector', frame1)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어깨 인식\n",
    "# 오류 잡음\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def Rotate(src, degrees):\n",
    "    if degrees == 90:\n",
    "        dst = cv2.transpose(src) # 행렬 변경 \n",
    "        dst = cv2.flip(dst, 1)   # 뒤집기\n",
    "\n",
    "    elif degrees == 180:\n",
    "        dst = cv2.flip(src, 0)   # 뒤집기\n",
    "\n",
    "    elif degrees == 270:\n",
    "        dst = cv2.transpose(src) # 행렬 변경\n",
    "        dst = cv2.flip(dst, 0)   # 뒤집기\n",
    "    else:\n",
    "        dst = null\n",
    "    return dst\n",
    "\n",
    "cap = cv2.VideoCapture('HUN.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    if ret :\n",
    "        img = Rotate(img,90)\n",
    "        cv2.rectangle(img,(300,300),(100,100),(0,255,0),0)\n",
    "        crop_img = img[300:500, 150:360]\n",
    "        grey = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "        value = (35, 35)\n",
    "        blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "        _, thresh1 = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        #cv2.imshow('Thresholded', thresh1)\n",
    "        _,contours, hierarchy = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        max_area = -1\n",
    "\n",
    "        for i in range(len(contours)):\n",
    "            cnt=contours[i]\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if(area>max_area):\n",
    "                max_area=area\n",
    "                ci=i\n",
    "\n",
    "        cnt=contours[ci]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(crop_img,(x,y),(x+w,y+h),(0,0,255),0)\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        drawing = np.zeros(crop_img.shape,np.uint8)\n",
    "        cv2.drawContours(drawing,[cnt],0,(0,255,0),0)\n",
    "        cv2.drawContours(drawing,[hull],0,(0,0,255),0)\n",
    "        hull = cv2.convexHull(cnt,returnPoints = False)\n",
    "        defects = cv2.convexityDefects(cnt,hull)\n",
    "        count_defects = 0\n",
    "        cv2.drawContours(thresh1, contours, -1, (0,255,0), 3)\n",
    "\n",
    "        for i in range(defects.shape[0]):\n",
    "            s,e,f,d = defects[i,0]\n",
    "            start = tuple(cnt[s][0])\n",
    "            end = tuple(cnt[e][0])\n",
    "            far = tuple(cnt[f][0])\n",
    "            a = math.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "            b = math.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "            c = math.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "            angle = math.acos((b**2 + c**2 - a**2)/(2*b*c)) * 57\n",
    "            if angle <= 90:\n",
    "                count_defects += 1\n",
    "                cv2.circle(crop_img,far,1,[0,0,255],-1)\n",
    "            #dist = cv2.pointPolygonTest(cnt,far,True)\n",
    "            cv2.line(crop_img,start,end,[0,255,0],2)\n",
    "            #cv2.circle(crop_img,far,5,[0,0,255],-1)\n",
    "        if count_defects == 1:\n",
    "            cv2.putText(img,\"cnt_defects : 1\", (5,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        elif count_defects == 2:\n",
    "            str = \"cnt_defects : 2\"\n",
    "            cv2.putText(img, str, (5,50), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "        elif count_defects == 3:\n",
    "            cv2.putText(img,\"cnt_defects : 4?\", (5,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        elif count_defects == 4:\n",
    "            cv2.putText(img,\"cnt_defects : 4\", (5,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        else:\n",
    "            cv2.putText(img,\"cnt_defects : ?\", (5,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        #cv2.imshow('drawing', drawing)\n",
    "        #cv2.imshow('end', crop_img)\n",
    "        cv2.imshow('Gesture', img)\n",
    "        all_img = np.hstack((drawing, crop_img))\n",
    "        cv2.imshow('Contours', all_img)\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == 27:\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
