{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smile 뜨게 만드는 작업 했어욯ㅎㅎ\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "eyeCascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_eye.xml')\n",
    "mouthCascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_mcs_mouth.xml')\n",
    "\n",
    "video_capture = cv2.VideoCapture('facevideo.mp4')\n",
    "\n",
    "def findMouth(frame, eyes, faces):\n",
    "    mouths = mouthCascade.detectMultiScale(\n",
    "            frame,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=8,\n",
    "            minSize=(30, 10),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    if len(mouths) <= 0:\n",
    "        return 0, 0, 0, 0\n",
    "\n",
    "    eyeBottom = 0\n",
    "\n",
    "    for eye in eyes:\n",
    "        eyeX, eyeY, eyeW, eyeH = eye\n",
    "        if (eyeY + eyeH) > eyeBottom:\n",
    "            eyeBottom = eyeY + eyeH\n",
    "\n",
    "    faceX, faceY, faceW, faceH = faces[0]\n",
    "    faceBottom = faceY + faceH\n",
    "\n",
    "    for mouth in mouths:\n",
    "        mouthX, mouthY, mouthW, mouthH = mouth\n",
    "        if mouthY > (eyeBottom + 50) and (mouthY + mouthH) < faceBottom:\n",
    "            return mouth\n",
    "\n",
    "    return 0, 0, 0, 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.equalizeHist(gray)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=6,\n",
    "            minSize=(50, 50),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "        eyes = eyeCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=6,\n",
    "            minSize=(50, 50),\n",
    "            flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "\n",
    "        # Draw a rectangle around the faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "        # Draw a rectangle around the eyes\n",
    "        if len(eyes) >= 2:\n",
    "            eyes = eyes[:2]\n",
    "        for (x, y, w, h) in eyes:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        \n",
    "        # Draw a rectangle around the mouth\n",
    "        if len(faces) > 0 and len(eyes) > 0:\n",
    "            x, y, w, h = findMouth(gray2, eyes, faces)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame,'Smile',(x,y-7), 3, 1.2, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b5bc31dd7a5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcrop_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mgrey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "cap = cv2.VideoCapture('CHARLIE PUTH - How Long  Kyle Hanagami Choreography')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    cv2.rectangle(img,(300,300),(100,100),(0,255,0),0)\n",
    "    crop_img = img[100:300, 100:300]\n",
    "    grey = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "    value = (35, 35)\n",
    "    blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "    _, thresh1 = cv2.threshold(blurred, 127, 255,\n",
    "                               cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    cv2.imshow('Thresholded', thresh1)\n",
    "    contours, hierarchy = cv2.findContours(thresh1.copy(),cv2.RETR_TREE, \\\n",
    "            cv2.CHAIN_APPROX_NONE)\n",
    "    max_area = -1\n",
    "    for i in range(len(contours)):\n",
    "        cnt=contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area>max_area):\n",
    "            max_area=area\n",
    "            ci=i\n",
    "    cnt=contours[ci]\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(crop_img,(x,y),(x+w,y+h),(0,0,255),0)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    drawing = np.zeros(crop_img.shape,np.uint8)\n",
    "    cv2.drawContours(drawing,[cnt],0,(0,255,0),0)\n",
    "    cv2.drawContours(drawing,[hull],0,(0,0,255),0)\n",
    "    hull = cv2.convexHull(cnt,returnPoints = False)\n",
    "    defects = cv2.convexityDefects(cnt,hull)\n",
    "    count_defects = 0\n",
    "    cv2.drawContours(thresh1, contours, -1, (0,255,0), 3)\n",
    "    for i in range(defects.shape[0]):\n",
    "        s,e,f,d = defects[i,0]\n",
    "        start = tuple(cnt[s][0])\n",
    "        end = tuple(cnt[e][0])\n",
    "        far = tuple(cnt[f][0])\n",
    "        a = math.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)\n",
    "        b = math.sqrt((far[0] - start[0])**2 + (far[1] - start[1])**2)\n",
    "        c = math.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)\n",
    "        angle = math.acos((b**2 + c**2 - a**2)/(2*b*c)) * 57\n",
    "        if angle <= 90:\n",
    "            count_defects += 1\n",
    "            cv2.circle(crop_img,far,1,[0,0,255],-1)\n",
    "        #dist = cv2.pointPolygonTest(cnt,far,True)\n",
    "        cv2.line(crop_img,start,end,[0,255,0],2)\n",
    "        #cv2.circle(crop_img,far,5,[0,0,255],-1)\n",
    "    if count_defects == 1:\n",
    "        cv2.putText(img,\"I'M VIKRANT SHARMA\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    elif count_defects == 2:\n",
    "        str = \"THIS IS A BASIC HAND GESTURE RECOGNISER!!\"\n",
    "        cv2.putText(img, str, (5,50), cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    elif count_defects == 3:\n",
    "        cv2.putText(img,\"This is FOUR (:\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    elif count_defects == 4:\n",
    "        cv2.putText(img,\"HARE KRSNA\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    else:\n",
    "        cv2.putText(img,\"GOOD AFTERNOON TEACHERS\", (50,50),\\\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "    #cv2.imshow('drawing', drawing)\n",
    "    #cv2.imshow('end', crop_img)\n",
    "    cv2.imshow('Gesture', img)\n",
    "    all_img = np.hstack((drawing, crop_img))\n",
    "    cv2.imshow('Contours', all_img)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
