{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴인식\n",
    "face_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('facevideo.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in face_rects:\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "\n",
    "        cv2.imshow('Face Detector', frame)\n",
    "\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background Subtraction 배경 지우기\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "# bgsegm을 포함해야 됨.\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        cv2.imshow('frame', fgmask)\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "\n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body 인식하기\n",
    "\n",
    "cap = cv2.VideoCapture('CHARLIE PUTH - How Long  Kyle Hanagami Choreography.mp4')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "cv2.namedWindow('Face')\n",
    "face_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(grayframe, 1.8, 2, 0, (30, 30))\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0),3,4,0)\n",
    "        cv2.putText(frame, 'Detected human',(x-5,y-5), font, 0.9, (255,255,0),2)\n",
    "        \n",
    "    cv2.imshow('Face',frame)\n",
    "    \n",
    "    c = cv2.waitKey(10)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\bld\\opencv_1520732670222\\work\\opencv-3.4.1\\modules\\core\\src\\arithm.cpp:241: error: (-215) (mtype == 0 || mtype == 1) && _mask.sameSize(*psrc1) in function cv::binary_op\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c820ab3fbdaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmask_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mmasked_face\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_mask_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_mask_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mmasked_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_roi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_roi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_face\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\bld\\opencv_1520732670222\\work\\opencv-3.4.1\\modules\\core\\src\\arithm.cpp:241: error: (-215) (mtype == 0 || mtype == 1) && _mask.sameSize(*psrc1) in function cv::binary_op\n"
     ]
    }
   ],
   "source": [
    "# 가면쓰는거...내 컴퓨터에서는 되지 않아..ㅠㅠ\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "face_mask = cv2.imread('mask.jpg')\n",
    "h_mask, w_mask = face_mask.shape[:2]\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "cap = cv2.VideoCapture('facevideo.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        if h > 0 and w > 0:\n",
    "            x = int(x + 0.1*w)\n",
    "            y = int(y + 0.4*h)\n",
    "            w = int(0.8 * w)\n",
    "            h = int(0.8 * h)\n",
    "\n",
    "            frame_roi = frame[y:y+h, x:x+w] \n",
    "            face_mask_small = cv2.resize(face_mask, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(gray_mask, 50, 255, cv2.THRESH_BINARY)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "            masked_face = cv2.bitwise_and(face_mask_small, face_mask_small, mask=mask)\n",
    "            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "            frame[y:y+h, x:x+w] = cv2.add(masked_face, masked_frame)\n",
    "\n",
    "    cv2.imshow('Face Detector', frame)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지에서 눈동자인식\n",
    "\n",
    "img = cv2.imread('face.jpg')\n",
    "scaling_factor = 0.7\n",
    "\n",
    "img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Face', img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh_gray = cv2.threshold(gray,220,255,cv2.THRESH_BINARY)\n",
    "# 윤곽선을 찾는 것\n",
    "value, contours, hierarchy = cv2.findContours(thresh_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for contour in contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    rect = cv2.boundingRect(contour)\n",
    "    x,y,width,height=rect\n",
    "    radius = 0.25*(width+height)\n",
    "    \n",
    "    area_condition = (100<=area<=200)\n",
    "    symmetry_condition = (abs(1-float(width)/float(height))<=0.2)\n",
    "    fill_condition = (abs(1-(area/(math.pi*math.pow(radius,2.0))))<=0.3)\n",
    "    \n",
    "    if area_condition and symmetry_condition and fill_condition:\n",
    "        cv2.circle(img,(int(x+radius), int(y+radius)), int(1.3*radius),(0,180,0),-1)\n",
    "        \n",
    "    cv2.imshow('Pupil Detector', img)\n",
    "    c=cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지에서 눈동자인식\n",
    "\n",
    "img = cv2.imread('face.jpg')\n",
    "scaling_factor = 0.7\n",
    "\n",
    "img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Face', img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh_gray = cv2.threshold(gray,220,255,cv2.THRESH_BINARY)\n",
    "# 윤곽선을 찾는 것\n",
    "value, contours, hierarchy = cv2.findContours(thresh_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for contour in contours:\n",
    "    area = cv2.contourArea(contour)\n",
    "    rect = cv2.boundingRect(contour)\n",
    "    x,y,width,height=rect\n",
    "    radius = 0.25*(width+height)\n",
    "    \n",
    "    area_condition = (100<=area<=200)\n",
    "    symmetry_condition = (abs(1-float(width)/float(height))<=0.2)\n",
    "    fill_condition = (abs(1-(area/(math.pi*math.pow(radius,2.0))))<=0.3)\n",
    "    \n",
    "    if area_condition and symmetry_condition and fill_condition:\n",
    "        cv2.circle(img,(int(x+radius), int(y+radius)), int(1.3*radius),(0,180,0),-1)\n",
    "        \n",
    "cv2.imshow('Pupil Detector', img)\n",
    "c=cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width 1280.0, height 720.0, fps 30.0\n"
     ]
    }
   ],
   "source": [
    "# 동그라미로 얼굴 인식을 하는데 이게 더 잘 되는 것 같음\n",
    "\n",
    "#!/opt/local/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "\n",
    "#재생할 파일 \n",
    "VIDEO_FILE_PATH = 'facevideo.mp4'\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(VIDEO_FILE_PATH)\n",
    "\n",
    "#잘 열렸는지 확인\n",
    "if cap.isOpened() == False:\n",
    "    print ('Can\\'t open the video (%d)' % (VIDEO_FILE_PATH))\n",
    "    exit()\n",
    "\n",
    "titles = ['orig']\n",
    "#윈도우 생성 및 사이즈 변경\n",
    "for t in titles:\n",
    "    cv2.namedWindow(t)\n",
    "\n",
    "#재생할 파일의 넓이 얻기\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "#재생할 파일의 높이 얻기\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "#재생할 파일의 프레임 레이트 얻기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print('width {0}, height {1}, fps {2}'.format(width, height, fps))\n",
    "\n",
    "#XVID가 제일 낫다고 함.\n",
    "#linux 계열 DIVX, XVID, MJPG, X264, WMV1, WMV2.\n",
    "#windows 계열 DIVX\n",
    "#저장할 비디오 코덱\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "#저장할 파일 이름\n",
    "filename = 'sprite_with_face_detect.avi'\n",
    "\n",
    "#파일 stream 생성\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, (int(width), int(height)))\n",
    "#filename : 파일 이름\n",
    "#fourcc : 코덱\n",
    "#fps : 초당 프레임 수\n",
    "#width : 넓이\n",
    "#height : 높이\n",
    "\n",
    "#얼굴 인식용\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "while(True):\n",
    "    #파일로 부터 이미지 얻기\n",
    "    ret, frame = cap.read()\n",
    "    #더 이상 이미지가 없으면 종료\n",
    "    #재생 다 됨\n",
    "    if frame is None:\n",
    "        break;\n",
    "\n",
    "    #얼굴인식 영상 처리\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur =  cv2.GaussianBlur(grayframe,(5,5), 0)\n",
    "    faces = face_cascade.detectMultiScale(blur, 1.8, 2, 0, (50, 50))\n",
    "\n",
    "    #원본 이미지에 얼굴 인식된 부분 표시\n",
    "    for (x,y,w,h) in faces:\n",
    "        cx = int(x+(w/2))\n",
    "        cy = int(y+(h/2))\n",
    "        cr = int(w/2)\n",
    "        cv2.circle(frame,(cx,cy),cr,(0,255,0),3)\n",
    "\n",
    "    # 얼굴 인식된 이미지 화면 표시\n",
    "    cv2.imshow(titles[0],frame)\n",
    "\n",
    "    # 인식된 이미지 파일로 저장\n",
    "    out.write(frame)\n",
    "\n",
    "    #1ms 동안 키입력 대기\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break;\n",
    "\n",
    "\n",
    "#재생 파일 종료\n",
    "cap.release()\n",
    "#저장 파일 종료\n",
    "out.release()\n",
    "#윈도우 종료\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 얼굴인식\n",
    "face_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('facevideo.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        minisize = (int(frame.shape[1]/3), int(frame.shape[0]/3))\n",
    "        miniframe = cv2.resize(frame, minisize)\n",
    "        \n",
    "        gray = cv2.cvtColor(miniframe, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = miniframe[y:y+h, x:x+w]\n",
    "            \n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            for (ex,ey,ew,eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), (0,255,0), 3)\n",
    "            \n",
    "        cv2.imshow('Face Detector', miniframe)\n",
    "\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('D:/javaForever/util/opencv/sources/data/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('face.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "    cropped = img[y - int(h/4):y + h + int(h/4), x - int(w/4):x + w + int(w/4)]\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_casecade.detectMultiScale(roi_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Image view', cropped)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
