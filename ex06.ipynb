{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencv를 위한 머신러닝\n",
    "\n",
    "딥러닝과 머신러닝의 차이점\n",
    "\n",
    "인공 지능이 가장 큰 원이고, 그 다음이 머신 러닝이며, 현재의 인공지능 붐을 주도하는 딥 러닝이 가장 작은 원이라 할 수 있다.\n",
    "머신 러닝: 인공 지능을 구현하는 구체적 접근 방식\n",
    "딥 러닝: 완전한 머신 러닝을 실현하는 기술"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-edc43d17263f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load the jpg file into a numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_image_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"face.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"face.jpg\")\n",
    "\n",
    "# Find all the faces in the image using the default HOG-based model.\n",
    "# This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated.\n",
    "# See also: find_faces_in_picture_cnn.py\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import sqlite3\n",
    "import os\n",
    "conn = sqlite3.connect('database.db')\n",
    "if not os.path.exists('./dataset'):\n",
    "    os.makedirs('./dataset')\n",
    "c = conn.cursor()\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "uname = input(\"Enter your name: \")\n",
    "c.execute('INSERT INTO users (name) VALUES (?)', (uname,))\n",
    "uid = c.lastrowid\n",
    "sampleNum = 0\n",
    "while True:\n",
    "  ret, img = cap.read()\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "  for (x,y,w,h) in faces:\n",
    "    sampleNum = sampleNum+1\n",
    "    cv2.imwrite(\"dataset/User.\"+str(uid)+\".\"+str(sampleNum)+\".jpg\",gray[y:y+h,x:x+w])\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    cv2.waitKey(100)\n",
    "  cv2.imshow('img',img)\n",
    "  cv2.waitKey(1);\n",
    "  if sampleNum > 20:\n",
    "    break\n",
    "cap.release()\n",
    "conn.commit()\n",
    "conn.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "path = 'dataset'\n",
    "if not os.path.exists('./recognizer'):\n",
    "    os.makedirs('./recognizer')\n",
    "def getImagesWithID(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]\n",
    "    faces = []\n",
    "    IDs = []\n",
    "    for imagePath in imagePaths:\n",
    "        faceImg = Image.open(imagePath).convert('L')\n",
    "        faceNp = np.array(faceImg,'uint8')\n",
    "        ID = int(os.path.split(imagePath)[-1].split('.')[1])\n",
    "        faces.append(faceNp)\n",
    "        IDs.append(ID)\n",
    "        cv2.imshow(\"training\",faceNp)\n",
    "        cv2.waitKey(10)\n",
    "    return np.array(IDs), faces\n",
    "Ids, faces = getImagesWithID(path)\n",
    "recognizer.train(faces,Ids)\n",
    "#recognizer.save('recognizer/trainingData.yml')\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
